{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Clasificaci√≥n de la Enfermedad de Alzheimer\n",
    "Integrantes\n",
    "- Diego Alexander Hern√°ndez Silvestre - 21270\n",
    "- Linda In√©s Jim√©nez Vides - 21169\n",
    "- Mario Antonio Guerra Morales - 21008\n",
    "- Kristopher Javier Alvarado L√≥pez - 21188"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìä Balanceo de Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando augmentaci√≥n en MildDemented. Tama√±o actual: 717.\n",
      "Aplicando augmentaci√≥n en ModerateDemented. Tama√±o actual: 52.\n",
      "Aplicando augmentaci√≥n en NonDemented. Tama√±o actual: 2560.\n",
      "Aplicando augmentaci√≥n en VeryMildDemented. Tama√±o actual: 1792.\n"
     ]
    }
   ],
   "source": [
    "# Definir las transformaciones que aplicar√°s\n",
    "augmentations = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=10),  # Rotaci√≥n de ¬±10 grados\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.02, 0.02)),  # Desplazamiento horizontal/vertical 2%\n",
    "    transforms.RandomResizedCrop(size=(224, 224), scale=(0.92, 1.08)),  # Zoom hasta 8%\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Clase personalizada para cargar im√°genes desde carpetas\n",
    "class DementiaDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_list = os.listdir(image_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_list[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "# Directorios de las carpetas de im√°genes\n",
    "folders = {\n",
    "    \"MildDemented\": \"data/train/MildDemented\",\n",
    "    \"ModerateDemented\": \"data/train/ModerateDemented\",\n",
    "    \"NonDemented\": \"data/train/NonDemented\",\n",
    "    \"VeryMildDemented\": \"data/train/VeryMildDemented\"\n",
    "}\n",
    "\n",
    "target_size = 3200  # N√∫mero objetivo de im√°genes por clase\n",
    "\n",
    "# Funci√≥n para aplicar augmentaci√≥n y guardar nuevas im√°genes\n",
    "def augment_and_save(dataset, save_dir, current_size, target_size):\n",
    "    counter = current_size\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "    while counter < target_size:\n",
    "        for batch in loader:\n",
    "            augmented_img = transforms.ToPILImage()(batch[0])  # Convertir tensor a imagen PIL\n",
    "            augmented_img.save(os.path.join(save_dir, f'augmented_{counter}.jpg'))  # Guardar imagen\n",
    "            counter += 1\n",
    "            if counter >= target_size:\n",
    "                break\n",
    "\n",
    "# Iterar sobre cada carpeta\n",
    "for label, folder in folders.items():\n",
    "    current_images = os.listdir(folder)\n",
    "    current_size = len(current_images)\n",
    "    \n",
    "    if current_size < target_size:\n",
    "        print(f\"Aplicando augmentaci√≥n en {label}. Tama√±o actual: {current_size}.\")\n",
    "        \n",
    "        # Cargar el dataset de la clase actual\n",
    "        dataset = DementiaDataset(image_dir=folder, transform=augmentations)\n",
    "        \n",
    "        # Aumentar im√°genes y guardar\n",
    "        augment_and_save(dataset, folder, current_size, target_size)\n",
    "        \n",
    "    else:\n",
    "        print(f\"No se necesita augmentaci√≥n en {label}. Tama√±o actual: {current_size}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase: MildDemented. Tama√±o actual: 3200.\n",
      "Clase: ModerateDemented. Tama√±o actual: 3200.\n",
      "Clase: NonDemented. Tama√±o actual: 3200.\n",
      "Clase: VeryMildDemented. Tama√±o actual: 3200.\n"
     ]
    }
   ],
   "source": [
    "for label, folder in folders.items():\n",
    "    current_images = os.listdir(folder)\n",
    "    current_size = len(current_images)\n",
    "    print(f\"Clase: {label}. Tama√±o actual: {current_size}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üèãüèΩ‚Äç‚ôÄÔ∏è Divisi√≥n entrenamiento y validaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de im√°genes en train: 8960\n",
      "Total de im√°genes en validation: 3840\n",
      "Divisi√≥n de im√°genes de train en train/validation completada.\n"
     ]
    }
   ],
   "source": [
    "# Directorios donde se guardar√°n las im√°genes divididas\n",
    "train_folder = \"data/train/\"\n",
    "\n",
    "train_dir = \"new_data/train/\"\n",
    "val_dir = \"new_data/validation/\"\n",
    "\n",
    "# Crear los directorios de train y validation si no existen\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "# Contadores para el total de im√°genes en train y validation\n",
    "total_train_images = 0\n",
    "total_val_images = 0\n",
    "\n",
    "# Funci√≥n para dividir y copiar las im√°genes de train en train/validation\n",
    "def split_train_validation(train_folder, label, train_dir, val_dir, split_ratio=0.7):\n",
    "    global total_train_images, total_val_images\n",
    "    images = os.listdir(os.path.join(train_folder, label))\n",
    "    random.shuffle(images)\n",
    "    \n",
    "    # Calcular cu√°ntas im√°genes ir√°n a train y cu√°ntas a validation\n",
    "    split_index = int(len(images) * split_ratio)\n",
    "    train_images = images[:split_index]\n",
    "    val_images = images[split_index:]\n",
    "    \n",
    "    # Actualizar los contadores\n",
    "    total_train_images += len(train_images)\n",
    "    total_val_images += len(val_images)\n",
    "    \n",
    "    # Crear carpetas de train y validation para la clase actual\n",
    "    os.makedirs(os.path.join(train_dir, label), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_dir, label), exist_ok=True)\n",
    "    \n",
    "    # Copiar im√°genes de train\n",
    "    for img in train_images:\n",
    "        shutil.copy(os.path.join(train_folder, label, img), os.path.join(train_dir, label, img))\n",
    "    \n",
    "    # Copiar im√°genes de validation\n",
    "    for img in val_images:\n",
    "        shutil.copy(os.path.join(train_folder, label, img), os.path.join(val_dir, label, img))\n",
    "\n",
    "# Iterar sobre las carpetas de cada clase dentro de train\n",
    "for label in os.listdir(train_folder):\n",
    "    split_train_validation(train_folder, label, train_dir, val_dir, split_ratio=0.7)\n",
    "\n",
    "# Imprimir el total de im√°genes en train y validation\n",
    "print(f\"Total de im√°genes en train: {total_train_images}\")\n",
    "print(f\"Total de im√°genes en validation: {total_val_images}\")\n",
    "print(\"Divisi√≥n de im√°genes de train en train/validation completada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arquitectura del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n del dispositivo (GPU si est√° disponible)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Transformaciones (Aumento de datos y normalizaci√≥n)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Redimensionar las im√°genes\n",
    "    transforms.RandomHorizontalFlip(),  # Voltear horizontalmente\n",
    "    transforms.RandomRotation(10),  # Rotar aleatoriamente hasta 10 grados\n",
    "    transforms.ToTensor(),  # Convertir a tensor (esto convierte autom√°ticamente a float y escala a [0, 1])\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalizaci√≥n est√°ndar\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datasets de entrenamiento y validaci√≥n\n",
    "train_data = datasets.ImageFolder('new_data/train', transform=transform)\n",
    "val_data = datasets.ImageFolder('new_data/validation', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definici√≥n del modelo CNN basado en la arquitectura del art√≠culo\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)  # Entrada 224x224x3 -> Salida 224x224x32\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # Reduce 2x cada dimensi√≥n: 112x112x32 despu√©s de la 1ra convoluci√≥n\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # Entrada 112x112x32 -> Salida 112x112x64\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # Entrada 56x56x64 -> Salida 56x56x128\n",
    "        self.fc1 = nn.Linear(128 * 28 * 28, 512)  # Capa totalmente conectada, entrada 128*28*28 = 100352, salida 512\n",
    "        self.fc2 = nn.Linear(512, 4)  # Capa de salida, 4 clases para la clasificaci√≥n\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # Conv1 + MaxPool\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # Conv2 + MaxPool\n",
    "        x = self.pool(F.relu(self.conv3(x)))  # Conv3 + MaxPool\n",
    "        x = x.view(-1, 128 * 28 * 28)  # Aplanar para la capa totalmente conectada\n",
    "        x = F.relu(self.fc1(x))  # FC1\n",
    "        x = self.dropout(x)  # Dropout\n",
    "        x = self.fc2(x)  # FC2 - Salida final\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el modelo\n",
    "model = CNNModel().to(device)\n",
    "\n",
    "# Usar CrossEntropyLoss, que combina softmax y entrop√≠a cruzada\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Definir el optimizador\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Empieza el entrenamiento para la √©poca {epoch+1} \\n\")\n",
    "        model.train()  # Modo de entrenamiento\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Limpiar gradientes previos\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()  # Calcular gradientes\n",
    "            optimizer.step()  # Actualizar pesos\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(\"P√©rdida por √©poca calculada.\\n\")\n",
    "\n",
    "        # Validaci√≥n\n",
    "        model.eval()  # Modo de evaluaci√≥n (sin actualizaci√≥n de gradientes)\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        print(\"P√©rdida por validaci√≥n calculada.\\n\")\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        accuracy = correct / total\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    print('Entrenamiento completo.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empieza el entrenamiento para la √©poca 1 \n",
      "\n",
      "P√©rdida por √©poca calculada.\n",
      "\n",
      "P√©rdida por validaci√≥n calculada.\n",
      "\n",
      "Epoch [1/10], Loss: 1.0241, Val Loss: 0.6928, Val Accuracy: 0.6936\n",
      "Empieza el entrenamiento para la √©poca 2 \n",
      "\n",
      "P√©rdida por √©poca calculada.\n",
      "\n",
      "P√©rdida por validaci√≥n calculada.\n",
      "\n",
      "Epoch [2/10], Loss: 0.6910, Val Loss: 0.6064, Val Accuracy: 0.7091\n",
      "Empieza el entrenamiento para la √©poca 3 \n",
      "\n",
      "P√©rdida por √©poca calculada.\n",
      "\n",
      "P√©rdida por validaci√≥n calculada.\n",
      "\n",
      "Epoch [3/10], Loss: 0.6056, Val Loss: 0.5231, Val Accuracy: 0.7615\n",
      "Empieza el entrenamiento para la √©poca 4 \n",
      "\n",
      "P√©rdida por √©poca calculada.\n",
      "\n",
      "P√©rdida por validaci√≥n calculada.\n",
      "\n",
      "Epoch [4/10], Loss: 0.5416, Val Loss: 0.4639, Val Accuracy: 0.7892\n",
      "Empieza el entrenamiento para la √©poca 5 \n",
      "\n",
      "P√©rdida por √©poca calculada.\n",
      "\n",
      "P√©rdida por validaci√≥n calculada.\n",
      "\n",
      "Epoch [5/10], Loss: 0.5041, Val Loss: 0.4133, Val Accuracy: 0.8245\n",
      "Empieza el entrenamiento para la √©poca 6 \n",
      "\n",
      "P√©rdida por √©poca calculada.\n",
      "\n",
      "P√©rdida por validaci√≥n calculada.\n",
      "\n",
      "Epoch [6/10], Loss: 0.4658, Val Loss: 0.3726, Val Accuracy: 0.8447\n",
      "Empieza el entrenamiento para la √©poca 7 \n",
      "\n",
      "P√©rdida por √©poca calculada.\n",
      "\n",
      "P√©rdida por validaci√≥n calculada.\n",
      "\n",
      "Epoch [7/10], Loss: 0.4214, Val Loss: 0.3482, Val Accuracy: 0.8523\n",
      "Empieza el entrenamiento para la √©poca 8 \n",
      "\n",
      "P√©rdida por √©poca calculada.\n",
      "\n",
      "P√©rdida por validaci√≥n calculada.\n",
      "\n",
      "Epoch [8/10], Loss: 0.3879, Val Loss: 0.3145, Val Accuracy: 0.8695\n",
      "Empieza el entrenamiento para la √©poca 9 \n",
      "\n",
      "P√©rdida por √©poca calculada.\n",
      "\n",
      "P√©rdida por validaci√≥n calculada.\n",
      "\n",
      "Epoch [9/10], Loss: 0.3523, Val Loss: 0.2657, Val Accuracy: 0.8953\n",
      "Empieza el entrenamiento para la √©poca 10 \n",
      "\n",
      "P√©rdida por √©poca calculada.\n",
      "\n",
      "P√©rdida por validaci√≥n calculada.\n",
      "\n",
      "Epoch [10/10], Loss: 0.3271, Val Loss: 0.2370, Val Accuracy: 0.9084\n",
      "Entrenamiento completo.\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer)\n",
    "\n",
    "# Guardar el modelo\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi√≥n en el conjunto de validaci√≥n: 90.50%\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en los datos de validaci√≥n\n",
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    print(f'Precisi√≥n en el conjunto de validaci√≥n: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Evaluar el modelo\n",
    "evaluate_model(model, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
