{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Clasificaci√≥n de la Enfermedad de Alzheimer\n",
    "Integrantes\n",
    "- Diego Alexander Hern√°ndez Silvestre - 21270\n",
    "- Linda In√©s Jim√©nez Vides - 21169\n",
    "- Mario Antonio Guerra Morales - 21008\n",
    "- Kristopher Javier Alvarado L√≥pez - 21188"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìä Balanceo de Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando augmentaci√≥n en MildDemented. Tama√±o actual: 717.\n",
      "Aplicando augmentaci√≥n en ModerateDemented. Tama√±o actual: 52.\n",
      "Aplicando augmentaci√≥n en NonDemented. Tama√±o actual: 2560.\n",
      "Aplicando augmentaci√≥n en VeryMildDemented. Tama√±o actual: 1792.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Definir las transformaciones que aplicar√°s\n",
    "augmentations = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=10),  # Rotaci√≥n de ¬±10 grados\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.02, 0.02)),  # Desplazamiento horizontal/vertical 2%\n",
    "    transforms.RandomResizedCrop(size=(224, 224), scale=(0.92, 1.08)),  # Zoom hasta 8%\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Clase personalizada para cargar im√°genes desde carpetas\n",
    "class DementiaDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_list = os.listdir(image_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_list[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "# Directorios de las carpetas de im√°genes\n",
    "folders = {\n",
    "    \"MildDemented\": \"data/train/MildDemented\",\n",
    "    \"ModerateDemented\": \"data/train/ModerateDemented\",\n",
    "    \"NonDemented\": \"data/train/NonDemented\",\n",
    "    \"VeryMildDemented\": \"data/train/VeryMildDemented\"\n",
    "}\n",
    "\n",
    "# Directorios donde se guardar√°n las im√°genes aumentadas\n",
    "augmented_folders = {\n",
    "    \"MildDemented\": \"data/augmented/MildDemented\",\n",
    "    \"ModerateDemented\": \"data/augmented/ModerateDemented\",\n",
    "    \"NonDemented\": \"data/augmented/NonDemented\",\n",
    "    \"VeryMildDemented\": \"data/augmented/VeryMildDemented\"\n",
    "}\n",
    "\n",
    "target_size = 3200  # N√∫mero objetivo de im√°genes por clase\n",
    "\n",
    "# Crear los directorios para las im√°genes aumentadas si no existen\n",
    "for folder in augmented_folders.values():\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "# Funci√≥n para aplicar augmentaci√≥n y guardar nuevas im√°genes\n",
    "def augment_and_save(dataset, save_dir, target_size):\n",
    "    current_size = len(dataset)\n",
    "    images_to_generate = target_size  # Calcular cu√°ntas im√°genes generar para llegar a 3200\n",
    "    counter = 0  # Contador para las nuevas im√°genes aumentadas\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "    # Generar im√°genes hasta alcanzar el tama√±o objetivo\n",
    "    while counter < images_to_generate:\n",
    "        for batch in loader:\n",
    "            augmented_img = transforms.ToPILImage()(batch[0])  # Convertir tensor a imagen PIL\n",
    "            augmented_img.save(os.path.join(save_dir, f'augmented_{counter + current_size}.jpg'))  # Guardar imagen aumentada\n",
    "            counter += 1\n",
    "            if counter >= images_to_generate:\n",
    "                break\n",
    "\n",
    "# Iterar sobre cada carpeta de im√°genes originales\n",
    "for label, folder in folders.items():\n",
    "    current_images = os.listdir(folder)\n",
    "    current_size = len(current_images)\n",
    "        \n",
    "    # Si el tama√±o actual es menor a 3200, se realiza augmentaci√≥n\n",
    "    if current_size < target_size:\n",
    "        print(f\"Aplicando augmentaci√≥n en {label}. Tama√±o actual: {current_size}.\")\n",
    "        \n",
    "        # Cargar el dataset de la clase actual\n",
    "        dataset = DementiaDataset(image_dir=folder, transform=augmentations)\n",
    "        \n",
    "        \n",
    "        # Definir el directorio para guardar im√°genes aumentadas\n",
    "        save_dir = augmented_folders[label]\n",
    "        \n",
    "        # Aumentar im√°genes y guardar en la carpeta de im√°genes aumentadas\n",
    "        augment_and_save(dataset, save_dir, target_size)\n",
    "        \n",
    "    else:\n",
    "        print(f\"No se necesita augmentaci√≥n en {label}. Tama√±o actual: {current_size}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase: MildDemented. Tama√±o actual: 3200.\n",
      "Clase: ModerateDemented. Tama√±o actual: 3200.\n",
      "Clase: NonDemented. Tama√±o actual: 3200.\n",
      "Clase: VeryMildDemented. Tama√±o actual: 3200.\n"
     ]
    }
   ],
   "source": [
    "for label, folder in augmented_folders.items():\n",
    "    current_images = os.listdir(folder)\n",
    "    current_size = len(current_images)\n",
    "    print(f\"Clase: {label}. Tama√±o actual: {current_size}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üèãüèΩ‚Äç‚ôÄÔ∏è Divisi√≥n entrenamiento y validaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de im√°genes en train: 8960\n",
      "Total de im√°genes en validation: 3840\n",
      "Divisi√≥n de im√°genes de train en train/validation completada.\n"
     ]
    }
   ],
   "source": [
    "# Directorios donde se guardar√°n las im√°genes divididas\n",
    "train_folder = \"data/augmented/\"\n",
    "\n",
    "train_dir = \"new_data/train/\"\n",
    "val_dir = \"new_data/validation/\"\n",
    "\n",
    "# Crear los directorios de train y validation si no existen\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "# Contadores para el total de im√°genes en train y validation\n",
    "total_train_images = 0\n",
    "total_val_images = 0\n",
    "\n",
    "# Funci√≥n para dividir y copiar las im√°genes de train en train/validation\n",
    "def split_train_validation(train_folder, label, train_dir, val_dir, split_ratio=0.7):\n",
    "    global total_train_images, total_val_images\n",
    "    images = os.listdir(os.path.join(train_folder, label))\n",
    "    random.shuffle(images)\n",
    "    \n",
    "    # Calcular cu√°ntas im√°genes ir√°n a train y cu√°ntas a validation\n",
    "    split_index = int(len(images) * split_ratio)\n",
    "    train_images = images[:split_index]\n",
    "    val_images = images[split_index:]\n",
    "    \n",
    "    # Actualizar los contadores\n",
    "    total_train_images += len(train_images)\n",
    "    total_val_images += len(val_images)\n",
    "    \n",
    "    # Crear carpetas de train y validation para la clase actual\n",
    "    os.makedirs(os.path.join(train_dir, label), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_dir, label), exist_ok=True)\n",
    "    \n",
    "    # Copiar im√°genes de train\n",
    "    for img in train_images:\n",
    "        shutil.copy(os.path.join(train_folder, label, img), os.path.join(train_dir, label, img))\n",
    "    \n",
    "    # Copiar im√°genes de validation\n",
    "    for img in val_images:\n",
    "        shutil.copy(os.path.join(train_folder, label, img), os.path.join(val_dir, label, img))\n",
    "\n",
    "# Iterar sobre las carpetas de cada clase dentro de train\n",
    "for label in os.listdir(train_folder):\n",
    "    split_train_validation(train_folder, label, train_dir, val_dir, split_ratio=0.7)\n",
    "\n",
    "# Imprimir el total de im√°genes en train y validation\n",
    "print(f\"Total de im√°genes en train: {total_train_images}\")\n",
    "print(f\"Total de im√°genes en validation: {total_val_images}\")\n",
    "print(\"Divisi√≥n de im√°genes de train en train/validation completada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arquitectura del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n del dispositivo (GPU si est√° disponible)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Transformaciones (Aumento de datos y normalizaci√≥n)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Redimensionar las im√°genes\n",
    "    transforms.RandomHorizontalFlip(),  # Voltear horizontalmente\n",
    "    transforms.RandomRotation(10),  # Rotar aleatoriamente hasta 10 grados\n",
    "    transforms.ToTensor(),  # Convertir a tensor (esto convierte autom√°ticamente a float y escala a [0, 1])\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalizaci√≥n est√°ndar\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datasets de entrenamiento y validaci√≥n\n",
    "train_data = datasets.ImageFolder('new_data/train', transform=transform)\n",
    "val_data = datasets.ImageFolder('new_data/validation', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definici√≥n del modelo CNN basado en la arquitectura del art√≠culo\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)  # Entrada 224x224x3 -> Salida 224x224x32\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # Reduce 2x cada dimensi√≥n: 112x112x32 despu√©s de la 1ra convoluci√≥n\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # Entrada 112x112x32 -> Salida 112x112x64\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # Entrada 56x56x64 -> Salida 56x56x128\n",
    "        self.fc1 = nn.Linear(128 * 28 * 28, 512)  # Capa totalmente conectada, entrada 128*28*28 = 100352, salida 512\n",
    "        self.fc2 = nn.Linear(512, 4)  # Capa de salida, 4 clases para la clasificaci√≥n\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # Conv1 + MaxPool\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # Conv2 + MaxPool\n",
    "        x = self.pool(F.relu(self.conv3(x)))  # Conv3 + MaxPool\n",
    "        x = x.view(-1, 128 * 28 * 28)  # Aplanar para la capa totalmente conectada\n",
    "        x = F.relu(self.fc1(x))  # FC1\n",
    "        x = self.dropout(x)  # Dropout\n",
    "        x = self.fc2(x)  # FC2 - Salida final\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el modelo\n",
    "model = CNNModel().to(device)\n",
    "\n",
    "# Usar CrossEntropyLoss, que combina softmax y entrop√≠a cruzada\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Definir el optimizador\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Empieza el entrenamiento para la √©poca {epoch+1} \\n\")\n",
    "        model.train()  # Modo de entrenamiento\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Limpiar gradientes previos\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()  # Calcular gradientes\n",
    "            optimizer.step()  # Actualizar pesos\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(\"P√©rdida por √©poca calculada.\\n\")\n",
    "\n",
    "        # Validaci√≥n\n",
    "        model.eval()  # Modo de evaluaci√≥n (sin actualizaci√≥n de gradientes)\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        print(\"P√©rdida por validaci√≥n calculada.\\n\")\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        accuracy = correct / total\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    print('Entrenamiento completo.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empieza el entrenamiento para la √©poca 1 \n",
      "\n",
      "P√©rdida por √©poca calculada.\n",
      "\n",
      "P√©rdida por validaci√≥n calculada.\n",
      "\n",
      "Epoch [1/10], Loss: 1.2530, Val Loss: 0.9360, Val Accuracy: 0.5751\n",
      "Empieza el entrenamiento para la √©poca 2 \n",
      "\n",
      "P√©rdida por √©poca calculada.\n",
      "\n",
      "P√©rdida por validaci√≥n calculada.\n",
      "\n",
      "Epoch [2/10], Loss: 0.8672, Val Loss: 0.7747, Val Accuracy: 0.6434\n",
      "Empieza el entrenamiento para la √©poca 3 \n",
      "\n",
      "P√©rdida por √©poca calculada.\n",
      "\n",
      "P√©rdida por validaci√≥n calculada.\n",
      "\n",
      "Epoch [3/10], Loss: 0.7621, Val Loss: 0.6823, Val Accuracy: 0.6849\n",
      "Empieza el entrenamiento para la √©poca 4 \n",
      "\n",
      "P√©rdida por √©poca calculada.\n",
      "\n",
      "P√©rdida por validaci√≥n calculada.\n",
      "\n",
      "Epoch [4/10], Loss: 0.7006, Val Loss: 0.6425, Val Accuracy: 0.7134\n",
      "Empieza el entrenamiento para la √©poca 5 \n",
      "\n",
      "P√©rdida por √©poca calculada.\n",
      "\n",
      "P√©rdida por validaci√≥n calculada.\n",
      "\n",
      "Epoch [5/10], Loss: 0.6370, Val Loss: 0.5898, Val Accuracy: 0.7324\n",
      "Empieza el entrenamiento para la √©poca 6 \n",
      "\n",
      "P√©rdida por √©poca calculada.\n",
      "\n",
      "P√©rdida por validaci√≥n calculada.\n",
      "\n",
      "Epoch [6/10], Loss: 0.6057, Val Loss: 0.5526, Val Accuracy: 0.7457\n",
      "Empieza el entrenamiento para la √©poca 7 \n",
      "\n",
      "P√©rdida por √©poca calculada.\n",
      "\n",
      "P√©rdida por validaci√≥n calculada.\n",
      "\n",
      "Epoch [7/10], Loss: 0.5748, Val Loss: 0.5315, Val Accuracy: 0.7598\n",
      "Empieza el entrenamiento para la √©poca 8 \n",
      "\n",
      "P√©rdida por √©poca calculada.\n",
      "\n",
      "P√©rdida por validaci√≥n calculada.\n",
      "\n",
      "Epoch [8/10], Loss: 0.5417, Val Loss: 0.5049, Val Accuracy: 0.7646\n",
      "Empieza el entrenamiento para la √©poca 9 \n",
      "\n",
      "P√©rdida por √©poca calculada.\n",
      "\n",
      "P√©rdida por validaci√≥n calculada.\n",
      "\n",
      "Epoch [9/10], Loss: 0.5201, Val Loss: 0.4954, Val Accuracy: 0.7729\n",
      "Empieza el entrenamiento para la √©poca 10 \n",
      "\n",
      "P√©rdida por √©poca calculada.\n",
      "\n",
      "P√©rdida por validaci√≥n calculada.\n",
      "\n",
      "Epoch [10/10], Loss: 0.4970, Val Loss: 0.4790, Val Accuracy: 0.7794\n",
      "Entrenamiento completo.\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer)\n",
    "\n",
    "# Guardar el modelo\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi√≥n en el conjunto de validaci√≥n: 78.34%\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en los datos de validaci√≥n\n",
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    print(f'Precisi√≥n en el conjunto de validaci√≥n: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Crear una instancia del modelo y cargar el estado guardado\n",
    "model = CNNModel().to(device)\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "\n",
    "# Evaluar el modelo\n",
    "evaluate_model(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alvar\\OneDrive\\Documentos\\SemestreVIII\\Deep Learning\\Classification_of_Alzheimers_Disease\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (56) must match the size of tensor b (28) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Redimensionar inputs para que coincida con la entrada del modelo\u001b[39;00m\n\u001b[0;32m     18\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alvar\\OneDrive\\Documentos\\SemestreVIII\\Deep Learning\\Classification_of_Alzheimers_Disease\\myenv\\lib\\site-packages\\shap\\explainers\\_deep\\__init__.py:159\u001b[0m, in \u001b[0;36mDeepExplainer.shap_values\u001b[1;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshap_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, ranked_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, output_rank_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, check_additivity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return approximate SHAP values for the model applied to the data given by X.\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m \n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranked_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_rank_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_additivity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_additivity\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alvar\\OneDrive\\Documentos\\SemestreVIII\\Deep Learning\\Classification_of_Alzheimers_Disease\\myenv\\lib\\site-packages\\shap\\explainers\\_deep\\deep_pytorch.py:186\u001b[0m, in \u001b[0;36mPyTorchDeep.shap_values\u001b[1;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# run attribution computation graph\u001b[39;00m\n\u001b[0;32m    185\u001b[0m feature_ind \u001b[38;5;241m=\u001b[39m model_output_ranks[j, i]\n\u001b[1;32m--> 186\u001b[0m sample_phis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_ind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoint_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# assign the attributions to the right part of the output arrays\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterim:\n",
      "File \u001b[1;32mc:\\Users\\Alvar\\OneDrive\\Documentos\\SemestreVIII\\Deep Learning\\Classification_of_Alzheimers_Disease\\myenv\\lib\\site-packages\\shap\\explainers\\_deep\\deep_pytorch.py:119\u001b[0m, in \u001b[0;36mPyTorchDeep.gradient\u001b[1;34m(self, idx, inputs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(X):\n\u001b[1;32m--> 119\u001b[0m         grad \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselected\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    123\u001b[0m             grad \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\Alvar\\OneDrive\\Documentos\\SemestreVIII\\Deep Learning\\Classification_of_Alzheimers_Disease\\myenv\\lib\\site-packages\\torch\\autograd\\__init__.py:496\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[0;32m    492\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[0;32m    493\u001b[0m         grad_outputs_\n\u001b[0;32m    494\u001b[0m     )\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    507\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[0;32m    508\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[0;32m    509\u001b[0m     ):\n",
      "File \u001b[1;32mc:\\Users\\Alvar\\OneDrive\\Documentos\\SemestreVIII\\Deep Learning\\Classification_of_Alzheimers_Disease\\myenv\\lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "File \u001b[1;32mc:\\Users\\Alvar\\OneDrive\\Documentos\\SemestreVIII\\Deep Learning\\Classification_of_Alzheimers_Disease\\myenv\\lib\\site-packages\\torch\\utils\\hooks.py:139\u001b[0m, in \u001b[0;36mBackwardHook._set_user_hook.<locals>.hook\u001b[1;34m(grad_input, _)\u001b[0m\n\u001b[0;32m    136\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pack_with_none(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_tensors_index, grad_input, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_inputs)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_hooks:\n\u001b[1;32m--> 139\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alvar\\OneDrive\\Documentos\\SemestreVIII\\Deep Learning\\Classification_of_Alzheimers_Disease\\myenv\\lib\\site-packages\\shap\\explainers\\_deep\\deep_pytorch.py:241\u001b[0m, in \u001b[0;36mdeeplift_grad\u001b[1;34m(module, grad_input, grad_output)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_type \u001b[38;5;129;01min\u001b[39;00m op_handler:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m op_handler[module_type]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear_1d\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m--> 241\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop_handler\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodule_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    243\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munrecognized nn.Module: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Alvar\\OneDrive\\Documentos\\SemestreVIII\\Deep Learning\\Classification_of_Alzheimers_Disease\\myenv\\lib\\site-packages\\shap\\explainers\\_deep\\deep_pytorch.py:326\u001b[0m, in \u001b[0;36mmaxpool\u001b[1;34m(module, grad_input, grad_output)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    322\u001b[0m     _, indices \u001b[38;5;241m=\u001b[39m pool_to_function[module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m](\n\u001b[0;32m    323\u001b[0m         module\u001b[38;5;241m.\u001b[39mx, module\u001b[38;5;241m.\u001b[39mkernel_size, module\u001b[38;5;241m.\u001b[39mstride, module\u001b[38;5;241m.\u001b[39mpadding,\n\u001b[0;32m    324\u001b[0m         module\u001b[38;5;241m.\u001b[39mdilation, module\u001b[38;5;241m.\u001b[39mceil_mode, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    325\u001b[0m     xmax_pos, rmax_pos \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mchunk(pool_to_unpool[module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m](\n\u001b[1;32m--> 326\u001b[0m         \u001b[43mgrad_output\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdiffs\u001b[49m, indices, module\u001b[38;5;241m.\u001b[39mkernel_size, module\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    327\u001b[0m         module\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mlist\u001b[39m(module\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape)), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    329\u001b[0m grad_input \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m grad_input]\n\u001b[0;32m    330\u001b[0m grad_input[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(torch\u001b[38;5;241m.\u001b[39mabs(delta_in) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-7\u001b[39m, torch\u001b[38;5;241m.\u001b[39mzeros_like(delta_in),\n\u001b[0;32m    331\u001b[0m                        (xmax_pos \u001b[38;5;241m+\u001b[39m rmax_pos) \u001b[38;5;241m/\u001b[39m delta_in)\u001b[38;5;241m.\u001b[39mrepeat(dup0)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (56) must match the size of tensor b (28) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "# Inicializar el explainer usando una peque√±a muestra de tu conjunto de entrenamiento\n",
    "# Usamos una peque√±a muestra para mejorar el rendimiento\n",
    "sample_data = next(iter(train_loader))[0][:100].to(device)  # Ejemplo con 100 im√°genes del conjunto de entrenamiento\n",
    "\n",
    "# Redimensionar sample_data para que coincida con la entrada del modelo\n",
    "sample_data = sample_data.view(-1, 3, 224, 224)\n",
    "\n",
    "# Inicializar el SHAP explainer\n",
    "explainer = shap.DeepExplainer(model, sample_data)\n",
    "\n",
    "# Obtenci√≥n de los SHAP values para un lote de im√°genes del conjunto de validaci√≥n\n",
    "inputs, _ = next(iter(val_loader))\n",
    "inputs = inputs.to(device)\n",
    "\n",
    "# Redimensionar inputs para que coincida con la entrada del modelo\n",
    "inputs = inputs.view(-1, 3, 224, 224)\n",
    "\n",
    "shap_values = explainer.shap_values(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alvar\\OneDrive\\Documentos\\SemestreVIII\\Deep Learning\\Classification_of_Alzheimers_Disease\\myenv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Alvar\\OneDrive\\Documentos\\SemestreVIII\\Deep Learning\\Classification_of_Alzheimers_Disease\\myenv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√âpoca [1/10], P√©rdida: 0.5928\n",
      "√âpoca [2/10], P√©rdida: 0.3427\n",
      "√âpoca [3/10], P√©rdida: 0.1968\n",
      "√âpoca [4/10], P√©rdida: 0.1362\n",
      "√âpoca [5/10], P√©rdida: 0.0773\n",
      "√âpoca [6/10], P√©rdida: 0.0775\n",
      "√âpoca [7/10], P√©rdida: 0.0555\n",
      "√âpoca [8/10], P√©rdida: 0.0725\n",
      "√âpoca [9/10], P√©rdida: 0.0447\n",
      "√âpoca [10/10], P√©rdida: 0.0402\n",
      "Precisi√≥n del modelo en el conjunto de prueba: 67.47%\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Output 0 of BackwardHookFunctionBackward is a view and is being modified inplace. This view was created inside a custom Function (or because an input was returned as-is) and the autograd logic to handle view+inplace would override the custom backward associated with the custom Function, leading to incorrect gradients. This behavior is forbidden. You can fix this by cloning the output of the custom Function.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 76\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Cargar valores SHAP usando DeepExplainer\u001b[39;00m\n\u001b[0;32m     75\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mDeepExplainer(model, images)\n\u001b[1;32m---> 76\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Visualizaci√≥n de los valores SHAP\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(shap_values)):\n",
      "File \u001b[1;32mc:\\Users\\Alvar\\OneDrive\\Documentos\\SemestreVIII\\Deep Learning\\Classification_of_Alzheimers_Disease\\myenv\\lib\\site-packages\\shap\\explainers\\_deep\\__init__.py:159\u001b[0m, in \u001b[0;36mDeepExplainer.shap_values\u001b[1;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshap_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, ranked_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, output_rank_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, check_additivity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return approximate SHAP values for the model applied to the data given by X.\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m \n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranked_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_rank_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_additivity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_additivity\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alvar\\OneDrive\\Documentos\\SemestreVIII\\Deep Learning\\Classification_of_Alzheimers_Disease\\myenv\\lib\\site-packages\\shap\\explainers\\_deep\\deep_pytorch.py:186\u001b[0m, in \u001b[0;36mPyTorchDeep.shap_values\u001b[1;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# run attribution computation graph\u001b[39;00m\n\u001b[0;32m    185\u001b[0m feature_ind \u001b[38;5;241m=\u001b[39m model_output_ranks[j, i]\n\u001b[1;32m--> 186\u001b[0m sample_phis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_ind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoint_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# assign the attributions to the right part of the output arrays\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterim:\n",
      "File \u001b[1;32mc:\\Users\\Alvar\\OneDrive\\Documentos\\SemestreVIII\\Deep Learning\\Classification_of_Alzheimers_Disease\\myenv\\lib\\site-packages\\shap\\explainers\\_deep\\deep_pytorch.py:101\u001b[0m, in \u001b[0;36mPyTorchDeep.gradient\u001b[1;34m(self, idx, inputs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    100\u001b[0m X \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mrequires_grad_() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m inputs]\n\u001b[1;32m--> 101\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m selected \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m outputs[:, idx]]\n\u001b[0;32m    103\u001b[0m grads \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Alvar\\OneDrive\\Documentos\\SemestreVIII\\Deep Learning\\Classification_of_Alzheimers_Disease\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1740\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1739\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alvar\\OneDrive\\Documentos\\SemestreVIII\\Deep Learning\\Classification_of_Alzheimers_Disease\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1750\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1753\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1754\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[12], line 19\u001b[0m, in \u001b[0;36mAlzheimerCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alvar\\OneDrive\\Documentos\\SemestreVIII\\Deep Learning\\Classification_of_Alzheimers_Disease\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1740\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1739\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alvar\\OneDrive\\Documentos\\SemestreVIII\\Deep Learning\\Classification_of_Alzheimers_Disease\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1750\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1753\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1754\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Alvar\\OneDrive\\Documentos\\SemestreVIII\\Deep Learning\\Classification_of_Alzheimers_Disease\\myenv\\lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alvar\\OneDrive\\Documentos\\SemestreVIII\\Deep Learning\\Classification_of_Alzheimers_Disease\\myenv\\lib\\site-packages\\torchvision\\models\\resnet.py:270\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    268\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[0;32m    269\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[1;32m--> 270\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n\u001b[0;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n",
      "File \u001b[1;32mc:\\Users\\Alvar\\OneDrive\\Documentos\\SemestreVIII\\Deep Learning\\Classification_of_Alzheimers_Disease\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1740\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1739\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alvar\\OneDrive\\Documentos\\SemestreVIII\\Deep Learning\\Classification_of_Alzheimers_Disease\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1848\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1845\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[0;32m   1847\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1848\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1850\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[0;32m   1852\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[0;32m   1853\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\Alvar\\OneDrive\\Documentos\\SemestreVIII\\Deep Learning\\Classification_of_Alzheimers_Disease\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1794\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1791\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[0;32m   1792\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1794\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m   1797\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1798\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1799\u001b[0m     ):\n\u001b[0;32m   1800\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alvar\\OneDrive\\Documentos\\SemestreVIII\\Deep Learning\\Classification_of_Alzheimers_Disease\\myenv\\lib\\site-packages\\torch\\nn\\modules\\activation.py:133\u001b[0m, in \u001b[0;36mReLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alvar\\OneDrive\\Documentos\\SemestreVIII\\Deep Learning\\Classification_of_Alzheimers_Disease\\myenv\\lib\\site-packages\\torch\\nn\\functional.py:1702\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1700\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(relu, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, inplace\u001b[38;5;241m=\u001b[39minplace)\n\u001b[0;32m   1701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m-> 1702\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1704\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Output 0 of BackwardHookFunctionBackward is a view and is being modified inplace. This view was created inside a custom Function (or because an input was returned as-is) and the autograd logic to handle view+inplace would override the custom backward associated with the custom Function, leading to incorrect gradients. This behavior is forbidden. You can fix this by cloning the output of the custom Function."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import shap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Definir el modelo CNN\n",
    "class AlzheimerCNN(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(AlzheimerCNN, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True)  # Usamos ResNet18 como base\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Inicializar el modelo, la funci√≥n de p√©rdida y el optimizador\n",
    "num_classes = 4\n",
    "model = AlzheimerCNN(num_classes=num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 2. Preparaci√≥n de los datos usando ImageFolder\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Cargar el dataset de entrenamiento usando ImageFolder\n",
    "train_dataset = ImageFolder(root='data/augmented', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Cargar el dataset de prueba usando ImageFolder\n",
    "# Aseg√∫rate de tener un conjunto de prueba organizado en carpetas por clase\n",
    "test_dataset = ImageFolder(root='data/test', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 3. Entrenamiento del modelo\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"√âpoca [{epoch + 1}/{num_epochs}], P√©rdida: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# 4. Evaluaci√≥n en conjunto de prueba\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f\"Precisi√≥n del modelo en el conjunto de prueba: {100 * correct / total:.2f}%\")\n",
    "\n",
    "# 5. C√°lculo y visualizaci√≥n de valores SHAP\n",
    "# Selecciona algunas im√°genes del conjunto de entrenamiento para el c√°lculo de SHAP\n",
    "sample_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "images, labels = next(iter(sample_loader))\n",
    "\n",
    "# Cargar valores SHAP usando DeepExplainer\n",
    "explainer = shap.DeepExplainer(model, images)\n",
    "shap_values = explainer.shap_values(images)\n",
    "\n",
    "# Visualizaci√≥n de los valores SHAP\n",
    "for i in range(len(shap_values)):\n",
    "    plt.figure()\n",
    "    shap.image_plot([shap_values[i]], images.numpy().transpose(0, 2, 3, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "# Guardar el modelo\n",
    "torch.save(model.state_dict(), 'modelo_alzheimer.pth')\n",
    "print(\"Modelo guardado exitosamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "model.eval()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
